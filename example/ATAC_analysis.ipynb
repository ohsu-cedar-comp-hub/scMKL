{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using scMKL with single-cell ATAC data\n",
    "Here we will run scMKL on a subset of the MCF-7 data (1,000 cells x 206,167 regions) using Hallmark groupings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules\n",
    "Data is read-in and saved using numpy and pickle modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages needed to import data\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "# This sys command allows us to import the scMKL_src_anndata module from any directory.\n",
    "# '..' can be replaced by any path to the repository directory \n",
    "sys.path.insert(0, '..')\n",
    "import scmkl\n",
    "\n",
    "# Modules for viewing results\n",
    "# import pandas as pd\n",
    "# from plotnine import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data\n",
    "There are 4 required pieces of data (per modality) required for scMKL\n",
    "- The data matrix itself with cells as rows and features as columns.\n",
    "    - Can be either a Numpy Array or Scipy Sparse array (scipy.sparse.csc_array is the recommended format).  \n",
    "- The sample labels in a Numpy Array.  To perform group lasso, these labels must be binary.\n",
    "- Feature names in a Numpy Array. These are the names of the features corresponding with the data matrix\n",
    "- A dictionary with grouping data.  The keys are the names of the groups, and the values are the corresponding features.\n",
    "    - Example: {Group1: [feature1, feature2, feature3], Group2: [feature4, feature5, feature6], ...}\n",
    "    - See `getting_ATAC_groupings.ipynb` for more information on creating peak sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in grouping dictionary from pickle file\n",
    "group_dict = np.load('./data/MCF7_ATAC_hallmark_groupings.pkl', allow_pickle = True)\n",
    "\n",
    "# Reading in data to be analyzed\n",
    "X = load_npz('./data/MCF7_ATAC_X.npz')\n",
    "cell_labels = np.load('./data/MCF7_cell_labels.npy', allow_pickle = True)\n",
    "feature_names = np.load('./data/MCF7_ATAC_feature_names.npy', allow_pickle = True)\n",
    "\n",
    "# This value for D, the number of fourier features in Z, was found to be optimal in previous literature. \n",
    "# Generally increasing D increases accuracy, but runs slower.\n",
    "D = int(np.sqrt(len(cell_labels)) * np.log(np.log(len(cell_labels))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an AnnData Object\n",
    "scMKL takes advantage of AnnData's flexible structure to create a straight-forward approach to running scMKL.\n",
    "`create_adata` requires: \n",
    "- `X` : A data matrix of cells by features can be a numpy array, scipy sparse array or pandas dataframe (sparse array recommended for large datasets)\n",
    "- `feature_names` : A numpy array of feature names corresponding with the features in `X`\n",
    "- `cell_labels` : A numpy array of cell phenotypes corresponding with the cells in X (must be binary)\n",
    "- `group_dict` : Dictionary containing feature grouping information\n",
    "    - Example: `{geneset: np.array(gene_1, gene_2, ..., gene_n)}`\n",
    "- `data_type` : `'counts'` or `'binary'`.  Determines what preprocessing is applied to the data\n",
    "    - Log transforms and standard scales counts data\n",
    "    - TFIDF filters binary data\n",
    "- `split_data` : Either numpy array of precalculated train/test split for the cells or `None`\n",
    "    - If `None`, the train test split will be calculated with balanced classes\n",
    "- `D` : Number of Random Fourier Features used to calculate Z. Should be a positive integer\n",
    "    - Higher values of D will increase classification accuracy at the cost of computation time\n",
    "- `remove_features` : Bool whether to filter the features from the dataset\n",
    "    - Will remove features from X, feature_names not in group_dict and remove features from groupings not in feature_names\n",
    "- `random_state` : Integer random_state used to set the seed for reproducibilty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = scmkl.create_adata(X = X, \n",
    "                         feature_names = feature_names, \n",
    "                         cell_labels = cell_labels, \n",
    "                         group_dict = group_dict,\n",
    "                         data_type = 'binary', \n",
    "                         D = D, \n",
    "                         remove_features = True, \n",
    "                         random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating Kernel Widths\n",
    "`sigma` refers to kernel widths of approximate kernels and should be estimated when running scMKL with `estimate_sigma()` with parameters:\n",
    "- `adata` : Adata obj as created by `create_adata`\n",
    "- `n_features` : Number of random features to include when estimating sigma\n",
    "    - Will be scaled for the whole pathway set according to a heuristic (for scalability)\n",
    "\n",
    "Returns adata object with sigma array in `adata.uns['sigma']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = scmkl.estimate_sigma(adata, n_features = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Z\n",
    "The Z matrices are a dimensional reduction of the original single-cell matrix grouped by group_dict groupings and separated by train/test split.\n",
    "\n",
    "Here we calculate Z using the `calculate_z` function with:\n",
    "- `adata` : Adata obj as created by `create_adata` with `'sigma'` key in `adata.uns`\n",
    "    - Sigma can be calculated with `estimate_sigma` or a heuristic but must be positive\n",
    "- `n_features` : Number of random features to use when calculating Z (used for scalability)\n",
    "\n",
    "Returns Z matrices for training and testing in adata object with `adata.uns['Z_train']` and `adata.uns['Z_test']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = scmkl.calculate_z(adata, n_features = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Sparsity\n",
    "Sparsity (lambda) or alpha here, is the regularization coefficient that controls the pentalty to run with the model.\n",
    "\n",
    "This will ultimately decide how many groups will be used in the final model.\n",
    "\n",
    "We can calculate the best performing sparsity argument from the training data using cross-validation with `optimize_alpha`, which requires:\n",
    "- `adata` : Anndata object with Z_train and Z_test calculated\n",
    "- `group_size` : Argument describing how the features are grouped\n",
    "    - From Celer documentation:\n",
    "        - \"groupsint | list of ints | list of lists of ints\n",
    "            - Partition of features used in the penalty on w\n",
    "                - If an int is passed, groups are contiguous blocks of features, of size groups\n",
    "                - If a list of ints is passed, groups are assumed to be contiguous, group number g being of size groups[g]\n",
    "                - If a list of lists of ints is passed, groups[g] contains the feature indices of the group number g\"\n",
    "        - If 1, model will behave identically to Lasso Regression\n",
    "- `tfidf` : Boolean value to determine if TFIDF normalization should be run at each fold. True means that it will be performed\n",
    "- `alpha_array` : Numpy array of all alpha values to be tested\n",
    "- `k` : number of folds to perform cross validation over\n",
    "\n",
    "Returns a single sparsity value as the optimal sparsity aregument for training the model\n",
    "\n",
    "**NOTE: This step take a while to run and may want to be skipped if running the model with multiple sparsity areguments.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      " Memory Usage: [0.0, 0.0] GB\n",
      "Fold 2:\n",
      " Memory Usage: [0.0, 0.0] GB\n",
      "Fold 3:\n",
      " Memory Usage: [0.0, 0.0] GB\n",
      "Fold 4:\n",
      " Memory Usage: [0.0, 0.0] GB\n"
     ]
    }
   ],
   "source": [
    "# Setting a list of alpha values to train the model with\n",
    "alpha_list = np.round(np.linspace(2.2,0.05,10), 2)\n",
    "\n",
    "# Calculating the best performing alpha from cross validation on training data\n",
    "alpha_star = scmkl.optimize_alpha(adata = adata, group_size = 2 * D, tfidf = False, alpha_array = alpha_list, k = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evalutating Model\n",
    "Here we will train and evaluate 10 models, each with a different `alpha`.\n",
    "\n",
    "`alpha` (or lambda) is a regularization coefficient that deterimines how many groupings will be used to classify the test cells in the final model. Here, we will evalutate the model using a range of alphas (`alpha_list`) to get a range of selected groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Evaluating model. Alpha: 2.2\n",
      "  Evaluating model. Alpha: 1.96\n",
      "  Evaluating model. Alpha: 1.72\n",
      "  Evaluating model. Alpha: 1.48\n",
      "  Evaluating model. Alpha: 1.24\n",
      "  Evaluating model. Alpha: 1.01\n",
      "  Evaluating model. Alpha: 0.77\n",
      "  Evaluating model. Alpha: 0.53\n",
      "  Evaluating model. Alpha: 0.29\n",
      "  Evaluating model. Alpha: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Variables to capture model performance and results\n",
    "metric_dict = {}\n",
    "selected_pathways = {}\n",
    "group_norms = {}\n",
    "group_names = list(group_dict.keys())\n",
    "predicted = {}\n",
    "auroc_array = np.zeros(alpha_list.shape)\n",
    "\n",
    "# Iterating through alpha list, training/testing models, and capturing results\n",
    "for i, alpha in enumerate(alpha_list):\n",
    "    \n",
    "    print(f'  Evaluating model. Alpha: {alpha}', flush = True)\n",
    "\n",
    "    adata = scmkl.train_model(adata, group_size= 2*D, alpha = alpha)\n",
    "    predicted[alpha], metric_dict[alpha] = scmkl.predict(adata, \n",
    "                                                       metrics = ['AUROC','F1-Score', 'Accuracy', 'Precision', 'Recall'])\n",
    "    selected_pathways[alpha] = scmkl.find_selected_groups(adata)\n",
    "    group_norms[alpha] = [np.linalg.norm(\n",
    "        adata.uns['model'].coef_[i * 2 * D: (i + 1) * 2 * D - 1]) for i in np.arange(len(group_names))]\n",
    "\n",
    "results = {'Metrics' : metric_dict,\n",
    "           'Selected_pathways' : selected_pathways,\n",
    "           'Norms' : group_norms,\n",
    "           'Predictions' : predicted,\n",
    "           'Group_names' : group_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance and Top Groups per Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Selected Groups\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelected_pathways\u001b[39m\u001b[38;5;124m'\u001b[39m][alpha]))\n\u001b[1;32m     11\u001b[0m     summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop Group\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup_names\u001b[39m\u001b[38;5;124m'\u001b[39m])[np\u001b[38;5;241m.\u001b[39mwhere(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNorms\u001b[39m\u001b[38;5;124m'\u001b[39m][alpha] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mmax\u001b[39m(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNorms\u001b[39m\u001b[38;5;124m'\u001b[39m][alpha]))])\n\u001b[0;32m---> 12\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(summary)\n\u001b[1;32m     13\u001b[0m alpha_star_auroc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(summary[summary[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlpha\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m alpha_star][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUROC\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "summary = {'Alpha' : [],\n",
    "           'AUROC' : [],\n",
    "           'Number of Selected Groups' : [],\n",
    "           'Top Group' : []}\n",
    "\n",
    "# Creating summary DataFrame for each model\n",
    "for alpha in alpha_list:\n",
    "    summary['Alpha'].append(alpha)\n",
    "    summary['AUROC'].append(results['Metrics'][alpha]['AUROC'])\n",
    "    summary['Number of Selected Groups'].append(len(results['Selected_pathways'][alpha]))\n",
    "    summary['Top Group'].append(*np.array(results['Group_names'])[np.where(results['Norms'][alpha] == max(results['Norms'][alpha]))])\n",
    "summary = pd.DataFrame(summary)\n",
    "alpha_star_auroc = float(summary[summary['Alpha'] == alpha_star]['AUROC'])\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Plotting AUROC from each alpha run\n",
    "(ggplot(summary, aes(x = 'Alpha', y = 'AUROC')) \n",
    " + geom_point(fill = 'blue', color = 'blue') \n",
    " + theme_classic() \n",
    " + ylim(0.6, 1)\n",
    " + scale_x_reverse(breaks = alpha_list)\n",
    " + annotate('text', x = alpha_star, y = alpha_star_auroc + 0.04, label='Alpha\\nStar\\n|')\n",
    " ).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scMKL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
